{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from docx import Document\n",
    "from google.genai import types\n",
    "import mimetypes\n",
    "import base64\n",
    "\n",
    "my_var = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(my_var)\n",
    "print(os.environ)\n",
    "\n",
    "# üîπ Constants\n",
    "COMPANY_ID = \"de86535f-7695-4aa4-9654-78906191298a\"\n",
    "LOGIN_URL = \"https://v1.cclhp.eu/api/users/login\"\n",
    "QUERY_URL = f\"https://v1.cclhp.eu/api/datasets/\"\n",
    "EMAIL = \"debug@debug.debug\"\n",
    "PASSWORD = \"debug@debug.debug\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "\n",
    "# üîπ Function to get JWT token\n",
    "def get_jwt_token():\n",
    "    payload = {\"email\": EMAIL, \"password\": PASSWORD}\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    response = requests.post(LOGIN_URL, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Command Center is Online‚úÖ\")\n",
    "        return response.json()[\"proxy_response\"][\"jwt_token\"]\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to authenticate: {response.status_code}, {response.text}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def extract_json(client,chat, response, jwt_token):\n",
    "    # Extract the JSON block\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", response.text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        data = json.loads(json_str)\n",
    "        print(\"Extracted JSON:\", data)\n",
    "            \n",
    "        # Route logic based on relevance\n",
    "        if data.get(\"relevance\", \"\").lower() == \"yes\":\n",
    "            handle_bi_relevant(client, chat, data, jwt_token)\n",
    "        else:\n",
    "            handle_non_bi_query(data)\n",
    "    else:\n",
    "        print(\"No JSON found in the response.\")\n",
    "        \n",
    "\n",
    "# üîπ Function to upload CSV file\n",
    "def extract_datasets(jwt_token):\n",
    "    headers = {\n",
    "        \"CCapi-company-id\": COMPANY_ID,\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(QUERY_URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Successfully Extracted Datasets!\")\n",
    "        print(response.text,response.status_code)\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"‚ùå Extraction failed: {response.status_code}, {response.text}\")\n",
    "\n",
    "def handle_bi_relevant(client, chat, data, jwt_token):\n",
    "    # Route logic based on data presence\n",
    "    if data.get(\"data_presence\", \"\").lower() == \"yes\":\n",
    "        handle_fully_relevant(client, chat, data,jwt_token)\n",
    "    else:\n",
    "        handle_partially_relevant(client,chat, data,jwt_token)\n",
    "    \n",
    "def handle_non_bi_query(data):\n",
    "    print(f\"Gemini: {data.get(\"answer\", \"\")}\")\n",
    "    #restart_chat()\n",
    "    \n",
    "def handle_fully_relevant(client, chat,data,jwt_token):\n",
    "    print(f\"Command Center Agent is connected via Gemini\")\n",
    "    datasets = extract_datasets(jwt_token)\n",
    "    # Send first message with system instruction + actual user query\n",
    "    variable = data.get(\"variable\", \"\")\n",
    "    chart_data = {\n",
    "        \"dataset_id\": \"your_dataset_id\",\n",
    "        \"title\": \"My Chart Title\",\n",
    "        \"chart_type\": \"line\",\n",
    "        \"chart_configuration\": {\n",
    "            \"config_type\": \"line_chart_config\",\n",
    "            \"background_colors\": [\"#ffffff\"],\n",
    "            \"border_colors\": [\"#000000\"],\n",
    "            \"dimension_field\": \"date\",\n",
    "            \"dimension_aggregation\": \"none\",\n",
    "            \"metrics\": [\n",
    "                {\n",
    "                    \"metric_field\": \"revenue\",\n",
    "                    \"metric_aggregation\": \"sum\"\n",
    "                }\n",
    "            ],\n",
    "            \"thresholds\": [\n",
    "                {\n",
    "                    \"metric_field\": \"revenue\",\n",
    "                    \"label\": \"Target\",\n",
    "                    \"value\": 10000,\n",
    "                    \"color\": \"red\",\n",
    "                    \"conditional_formatting\": {\n",
    "                        \"direction\": \"above\",\n",
    "                        \"tolerance\": 500\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"breakdown\": \"region\"\n",
    "        },\n",
    "        \"tags\": [\"finance\", \"monthly\", \"performance\"],\n",
    "        \"preferences\": {}\n",
    "    }\n",
    "\n",
    "    json_format = {\n",
    "        \"call_parameters\": {\n",
    "            \"date_from\": \"2025-04-17T00:00:00.000Z\",\n",
    "            \"date_to\": \"2025-04-17T23:59:59.000Z\",\n",
    "            \"page\": None,\n",
    "            \"sort_field\": None,\n",
    "            \"sort_order\": None,\n",
    "            \"filters\": None\n",
    "        },\n",
    "        \"headers\": {\n",
    "            \"CCapi-company-id\": \"de86535f-7695-4aa4-9654-78906191298a\"\n",
    "        },\n",
    "        \"request_payload\": {\n",
    "            \"dataset_id\": \"380a05d2-c3d8-498e-9b32-ebbd4d76561f\",\n",
    "            \"title\": \"Energy Consumption - Apparent Power\",\n",
    "            \"chart_type\": \"line\",\n",
    "            \"chart_configuration\": {\n",
    "                \"config_type\": \"line_chart_config\",\n",
    "                \"background_colors\": [\"#ffffff\"],\n",
    "                \"border_colors\": [\"#000000\"],\n",
    "                \"dimension_field\": \"timestamp_sensor\",\n",
    "                \"dimension_aggregation\": \"hours\",\n",
    "                \"metrics\": [\n",
    "                    {\n",
    "                        \"metric_field\": \"apparent_power\",\n",
    "                        \"metric_aggregation\": \"sum\"\n",
    "                    }\n",
    "                ],\n",
    "                \"thresholds\": [],\n",
    "                \"breakdown\": None\n",
    "            },\n",
    "            \"preferences\": {\n",
    "                \"multipleScale\": False\n",
    "            },\n",
    "            \"tags\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    file_path = \"API-DOCS (The lost documentation).docx\"\n",
    "\n",
    "    docx_content = read_docx(file_path)\n",
    "\n",
    "    system_instruction = (\n",
    "        f\"Now that you have extracted the relevant variable name for BI relevant queries, I want you to compare it with the datsets present in the BI tool \"\n",
    "        f\" The variable name is {variable}.\"\n",
    "        f\"The datasets are provided in the end \"\n",
    "        f\"If the variable is either directly present in a given dataset or can be represented as other variables in a dataset visualized together, I need you to create a json which is to be exported to the BI tool to extract relevant data and chart configuration \"\n",
    "        f\"organize the json in three entities: call parameters, headers and request payload\"\n",
    "        f\"the documentation reference for the call parameters, header and payload configuration is as follows\"\n",
    "        f\"{docx_content}\"\n",
    "        f\"The example format for payload is as follows\"\n",
    "        f\"{json.dumps(chart_data, indent=2)}\"\n",
    "        f\" final output json format is as follows\"\n",
    "        f\"{json_format}\"\n",
    "        #f\"If the variable is either directly present or can be calculated using multiple variables present in one dataset, create a json with if the dataset ahs been found as boolean and the name of the dataset \"t\n",
    "        f\"if the variable is not directly present or can't be represents using other variables present in one of the datasets, inform the user the same\"\n",
    "    )\n",
    "\n",
    "    response = chat.send_message(system_instruction + datasets)\n",
    "\n",
    "    chart_params = extract_data(response)\n",
    "\n",
    "    if chart_params is None:\n",
    "        print(\"Handle missing JSON case here.\")\n",
    "    else:\n",
    "        request_cc(client, chat,chart_params, jwt_token)\n",
    "\n",
    "    # Print chat\n",
    "    print(\"Assistant:\", response.text)\n",
    "    print(chart_params)\n",
    "\n",
    "def handle_partially_relevant(client,chat,data,jwt_token):\n",
    "    print(\"Assistant:\", data.get(\"missing_information\", \"\") )\n",
    "    user_query = input(\"User Input: \")\n",
    "    system_instruction = (\n",
    "        \"Check if the data provided by the user attached below along with the previous user input is now fully sufficient for BI tool input\"\n",
    "        \"If the full data is present accumulate the data using the same Json format mentioned before (relevance, data presence, etc). Same situation if the data is not fully present\"\n",
    "    )    \n",
    "    \n",
    "    response = chat.send_message(system_instruction + user_query)\n",
    "\n",
    "    print(\"Assistant:\", response.text)\n",
    "\n",
    "    extract_json(client,chat,response,jwt_token)\n",
    "\n",
    "\n",
    "def extract_data(response):\n",
    "# Extract the JSON block\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", response.text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        data = json.loads(json_str)\n",
    "        print(\"Extracted JSON:\", data)\n",
    "        return data\n",
    "                \n",
    "    else:\n",
    "        print(\"No JSON found in the response.\")\n",
    "        return None\n",
    "        \n",
    "def request_cc(client, chat, input_data, jwt_token):\n",
    "    base_url = \"https://v1.cclhp.eu/api/charts/preview\"\n",
    "    params = input_data[\"call_parameters\"]\n",
    "    query_params = {\n",
    "        \"date_from\": params[\"date_from\"],\n",
    "        \"date_to\": params[\"date_to\"]\n",
    "    }\n",
    "    # Add optional parameters if they are not None\n",
    "    if params.get(\"page\") is not None:\n",
    "        query_params[\"page\"] = params[\"page\"]\n",
    "    if params.get(\"sort_field\") is not None:\n",
    "        query_params[\"sort_field\"] = params[\"sort_field\"]\n",
    "    if params.get(\"sort_order\") is not None:\n",
    "        query_params[\"sort_order\"] = params[\"sort_order\"]\n",
    "\n",
    "    \n",
    "    # Final URL with query string\n",
    "    response = requests.post(\n",
    "        url=base_url,\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "            \"CCapi-company-id\": input_data[\"headers\"][\"CCapi-company-id\"]\n",
    "        },\n",
    "        params=query_params,\n",
    "        json=input_data[\"request_payload\"]\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    try:\n",
    "        print(\"Response JSON:\", response.json())\n",
    "        create_chart(client, chat, response.json)\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"Response Text:\", response.text)\n",
    "        \n",
    "def create_chart(client, chat, input):\n",
    "    system_instruction = (\n",
    "    f\"I would like you to generate the chart by yourself by writing your own code and exporting the final result as image to me \"\n",
    "    f\"The response (chart input) are as follows:\"\n",
    "    f\"{input}\"\n",
    "    f\"focus on the metric field datapoints for chart creation\"\n",
    "    f\"along with the chart image I would also request you to provide some text resonse about what could be some genereal statistics using the data points for the metric field keeping in mind what the user had initially requested\"\n",
    "    f\"just use the response provided to create the chart, dont show me the steps, elaborate or ask for additional input. All I need is the chart image and the statistics as text as response\"\n",
    "    )\n",
    "\n",
    "    print(system_instruction)\n",
    "\n",
    "    generate(client,system_instruction)\n",
    "\n",
    "    #response = chat.send_message(system_instruction)\n",
    "\n",
    "    #print(response)\n",
    "\n",
    "def save_binary_file(file_name, data):\n",
    "    f = open(file_name, \"wb\")\n",
    "    f.write(data)\n",
    "    f.close()\n",
    "\n",
    "def generate(client, input):\n",
    "\n",
    "    model = \"gemini-2.0-flash-exp-image-generation\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text= input),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_modalities=[\n",
    "            \"image\",\n",
    "            \"text\",\n",
    "        ],\n",
    "        response_mime_type=\"text/plain\",\n",
    "    )\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        if chunk.candidates is None or chunk.candidates[0].content is None or chunk.candidates[0].content.parts is None:\n",
    "            continue\n",
    "        if chunk.candidates[0].content.parts[0].inline_data:\n",
    "            file_name = \"chart\"\n",
    "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "            save_binary_file(\n",
    "                f\"{file_name}{file_extension}\", inline_data.data\n",
    "            )\n",
    "            print(\n",
    "                \"File of mime type\"\n",
    "                f\" {inline_data.mime_type} saved\"\n",
    "                f\"to: {file_name}\"\n",
    "            )\n",
    "        else:\n",
    "            print(chunk.text)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Center is Online‚úÖ\n",
      "**************Command Center Agent***********************\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client(api_key=my_var)\n",
    "\n",
    "# Create a chat (no system_instruction passed here)\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "\n",
    "try:\n",
    "    # Get JWT token\n",
    "    jwt_token = get_jwt_token()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(json.dumps({\"error\": str(e)}))\n",
    "\n",
    "\n",
    "print(f\"**************Command Center Agent***********************\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is the average hourly power consumption today?\n",
      "Assistant: ```json\n",
      "{\n",
      "  \"relevance\": \"yes\",\n",
      "  \"data_presence\": \"yes\",\n",
      "  \"variable\": \"power consumption\",\n",
      "  \"time_start\": \"00:00\",\n",
      "  \"time_end\": \"23:59\"\n",
      "}\n",
      "```\n",
      "\n",
      "Extracted JSON: {'relevance': 'yes', 'data_presence': 'yes', 'variable': 'power consumption', 'time_start': '00:00', 'time_end': '23:59'}\n",
      "Command Center Agent is connected via Gemini\n",
      "‚úÖ Successfully Extracted Datasets!\n",
      "[{\"name\":\"sensor\",\"description\":\"sensor\",\"data_schema\":{\"type\":\"object\",\"properties\":{\"timestamp_sensor\":{\"type\":\"string\",\"cc_def\":{\"type\":\"timestamp\"}},\"tension_l1_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"tension_l2_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"tension_l3_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"apparent_power\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}}}},\"timestamp_field\":\"timestamp_sensor\",\"tags\":null,\"auditable\":{\"created_by\":\"BI-REX@BI-REX.BI-REX\",\"last_update_by\":null,\"deleted_by\":null,\"created_server_date\":\"03/04/2025, 08:52:29\",\"created_local_time\":\"03/04/2025, 08:52:29\",\"last_update_server_date\":null,\"last_update_local_time\":null,\"deleted\":null,\"deleted_server_date\":null,\"deleted_local_time\":null},\"id\":\"de8980bd-27ee-4ffc-b31e-29212fede173\",\"company_id\":\"de86535f-7695-4aa4-9654-78906191298a\",\"owner_infos\":{\"company\":\"BI-REX\",\"company_id\":\"de86535f-7695-4aa4-9654-78906191298a\",\"email\":\"BI-REX@BI-REX.BI-REX\",\"first_name\":\"BI-REX\",\"last_name\":\"BI-REX\",\"role\":\"admin\",\"role_id\":2,\"user_id\":74}},{\"name\":\"Sensor_Data_Lorenzo\",\"description\":\"timestamp_sensor\",\"data_schema\":{\"type\":\"object\",\"properties\":{\"timestamp_sensor\":{\"type\":\"string\",\"cc_def\":{\"type\":\"timestamp\",\"scope\":\"\"},\"isReferenceTimestamp\":true},\"tension_l1_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"V\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"tension_l2_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"V\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"tension_l3_n\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"V\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"apparent_power\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"VA\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"real_power\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"W\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"power_factor\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"device_id\":{\"type\":\"string\",\"cc_def\":{\"type\":\"categorical\",\"scope\":\"nominal\"}},\"abs_real_power\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"W\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"reactive_power\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"VAr\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}},\"frequency\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\",\"format\":{\"type\":\"decimal\",\"options\":{\"digitsInfo\":{\"minIntegerDigits\":1,\"minFractionDigits\":0,\"maxFractionDigits\":2},\"suffix\":\"Hz\",\"splitBy100\":false,\"currencyCode\":\"EUR\"}}}}}},\"timestamp_field\":\"timestamp_sensor\",\"tags\":null,\"auditable\":{\"created_by\":\"raviteja.chandu@lhpeurope.com\",\"last_update_by\":\"raviteja.chandu@lhpeurope.com\",\"deleted_by\":null,\"created_server_date\":\"03/04/2025, 15:09:29\",\"created_local_time\":\"03/04/2025, 15:09:29\",\"last_update_server_date\":\"03/12/2025, 11:22:41\",\"last_update_local_time\":\"03/12/2025, 11:22:41\",\"deleted\":null,\"deleted_server_date\":null,\"deleted_local_time\":null},\"id\":\"380a05d2-c3d8-498e-9b32-ebbd4d76561f\",\"company_id\":\"de86535f-7695-4aa4-9654-78906191298a\",\"owner_infos\":{\"company\":\"N/A\",\"company_id\":0,\"email\":\"raviteja.chandu@lhpeurope.com\",\"first_name\":\"Raviteja\",\"last_name\":\"Chandu\",\"role\":\"superadmin\",\"role_id\":1,\"user_id\":73}},{\"name\":\"Birex_DMG_Test\",\"description\":\"Test Data\",\"data_schema\":{\"type\":\"object\",\"properties\":{\"device_id\":{\"type\":\"string\",\"cc_def\":{\"type\":\"categorical\",\"scope\":\"nominal\"}},\"timestamp\":{\"type\":\"string\",\"cc_def\":{\"type\":\"timestamp\",\"scope\":\"\"}},\"actspeed\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"toolposx\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"toolposy\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"toolposz\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"toolposc\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"toolposa\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"caricomandrino\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"temperaturamandrino\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"progstatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"xstatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"ystatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"zstatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cstatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"astatus\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"xbasepos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"ybasepos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"zbasepos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cbasepos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"abasepos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"xerrpos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"yerrpos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"zerrpos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cerrpos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"aerrpos\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"xvapower\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"yvapower\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"zvapower\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cvapower\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"avapower\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"vatorque\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"aatorque\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"xaacurr\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"yaacurr\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"zaacurr\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"caacurr\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"aaacurr\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"aavactm\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cmdfeedratex\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cmdfeedratey\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cmdfeedratez\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cmdfeedratec\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"cmdfeedratea\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"actfeedratex\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"actfeedratey\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"actfeedratez\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"actfeedratec\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}},\"actfeedratea\":{\"type\":\"number\",\"cc_def\":{\"type\":\"numerical\",\"scope\":\"continuous\"}}}},\"timestamp_field\":\"timestamp\",\"tags\":null,\"time_aggregations\":null,\"auditable\":{\"created_by\":\"raviteja.chandu@lhpeurope.com\",\"last_update_by\":null,\"deleted_by\":null,\"created_server_date\":\"04/02/2025, 13:43:29\",\"created_local_time\":\"04/02/2025, 13:43:29\",\"last_update_server_date\":null,\"last_update_local_time\":null,\"deleted\":null,\"deleted_server_date\":null,\"deleted_local_time\":null},\"id\":\"a9a7a47a-585c-40de-b644-13705c3f0386\",\"company_id\":\"de86535f-7695-4aa4-9654-78906191298a\",\"owner_infos\":{\"company\":\"N/A\",\"company_id\":0,\"email\":\"raviteja.chandu@lhpeurope.com\",\"first_name\":\"Raviteja\",\"last_name\":\"Chandu\",\"role\":\"superadmin\",\"role_id\":1,\"user_id\":73}}] 200\n",
      "Extracted JSON: {'call_parameters': {'date_from': '2025-04-17T00:00:00.000Z', 'date_to': '2025-04-17T23:59:59.000Z', 'page': None, 'sort_field': None, 'sort_order': None, 'filters': None}, 'headers': {'CCapi-company-id': 'de86535f-7695-4aa4-9654-78906191298a'}, 'request_payload': {'dataset_id': '380a05d2-c3d8-498e-9b32-ebbd4d76561f', 'title': 'Average Hourly Power Consumption', 'chart_type': 'line', 'chart_configuration': {'config_type': 'line_chart_config', 'background_colors': ['#ffffff'], 'border_colors': ['#000000'], 'dimension_field': 'timestamp_sensor', 'dimension_aggregation': 'hours', 'metrics': [{'metric_field': 'apparent_power', 'metric_aggregation': 'avg'}], 'thresholds': [], 'breakdown': None}, 'preferences': {'multipleScale': False}, 'tags': []}}\n",
      "Status Code: 200\n",
      "Response JSON: {'datapoints': {'chart_type': 'line', 'chart_title': 'Average Hourly Power Consumption', 'dimension_field': 'timestamp_sensor', 'dimensions': ['2025041700', '2025041701', '2025041702', '2025041703', '2025041704', '2025041705', '2025041706', '2025041707', '2025041708', '2025041709', '2025041710', '2025041711', '2025041712'], 'data': [{'key_name': 'apparent_power', 'metric_field': 'apparent_power', 'metric_aggregation': 'avg', 'metric_label': 'avg of apparent_power', 'background_color': '#ffffff', 'conditional_formatting_background_colors': None, 'border_color': '#000000', 'values': [2241.530084359121, 2237.712014229248, 2223.0476613559335, 2229.163491316846, 2259.6892998305107, 2242.5333419537005, 2237.10920254237, 2228.5512597740126, 2215.9205141807915, 2242.773683832672, 2250.316728870058, 2221.6041199547776, 2224.103279009232], 'thresholds': []}], 'default_dimension_aggregation': 'hours', 'selected_dimension_aggregation': 'hours'}, 'cc_def': {'timestamp_sensor': {'type': 'timestamp', 'scope': ''}, 'tension_l1_n': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'V', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'tension_l2_n': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'V', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'tension_l3_n': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'V', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'apparent_power': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'VA', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'real_power': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'W', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'power_factor': {'type': 'numerical', 'scope': 'continuous'}, 'device_id': {'type': 'categorical', 'scope': 'nominal'}, 'abs_real_power': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'W', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'reactive_power': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'VAr', 'splitBy100': False, 'currencyCode': 'EUR'}}}, 'frequency': {'type': 'numerical', 'scope': 'continuous', 'format': {'type': 'decimal', 'options': {'digitsInfo': {'minIntegerDigits': 1, 'minFractionDigits': 0, 'maxFractionDigits': 2}, 'suffix': 'Hz', 'splitBy100': False, 'currencyCode': 'EUR'}}}}, 'chart': {'dataset_id': '380a05d2-c3d8-498e-9b32-ebbd4d76561f', 'title': 'Average Hourly Power Consumption', 'chart_type': 'line', 'chart_configuration': {'config_type': 'line_chart_config', 'background_colors': ['#ffffff'], 'border_colors': ['#000000'], 'dimension_field': 'timestamp_sensor', 'dimension_aggregation': 'hours', 'metrics': [{'metric_field': 'apparent_power', 'metric_aggregation': 'avg'}], 'thresholds': [], 'breakdown': None}, 'tags': [], 'preferences': {'multipleScale': False}, 'auditable': {'created_by': 'debug@debug.debug', 'last_update_by': None, 'deleted_by': None, 'created_server_date': '04/17/2025, 12:41:41', 'created_local_time': '04/17/2025, 12:41:41', 'last_update_server_date': None, 'last_update_local_time': None, 'deleted': None, 'deleted_server_date': None, 'deleted_local_time': None}, 'company_id': 'de86535f-7695-4aa4-9654-78906191298a', 'id': 'ea96694d-6eb3-4c15-a9d9-be287ce45149'}, 'advanced_metrics': {}}\n",
      "I would like you to generate the chart by yourself by writing your own code and exporting the final result as image to me The response (chart input) are as follows:<bound method Response.json of <Response [200]>>focus on the metric field datapoints for chart creationalong with the chart image I would also request you to provide some text resonse about what could be some genereal statistics using the data points for the metric field keeping in mind what the user had initially requestedjust use the response provided to create the chart, dont show me the steps, elaborate or ask for additional input. All I need is the chart image and the statistics as text as response\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServerError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUser:\u001b[39m\u001b[33m\"\u001b[39m, user_question)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAssistant:\u001b[39m\u001b[33m\"\u001b[39m, response.text)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mextract_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjwt_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mextract_json\u001b[39m\u001b[34m(client, chat, response, jwt_token)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Route logic based on relevance\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mrelevance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).lower() == \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mhandle_bi_relevant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjwt_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     31\u001b[39m     handle_non_bi_query(data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mhandle_bi_relevant\u001b[39m\u001b[34m(client, chat, data, jwt_token)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandle_bi_relevant\u001b[39m(client, chat, data, jwt_token):\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Route logic based on data presence\u001b[39;00m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mdata_presence\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).lower() == \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[43mhandle_fully_relevant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mjwt_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     58\u001b[39m         handle_partially_relevant(client,chat, data,jwt_token)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mhandle_fully_relevant\u001b[39m\u001b[34m(client, chat, data, jwt_token)\u001b[39m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mHandle missing JSON case here.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[43mrequest_cc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjwt_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Print chat\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAssistant:\u001b[39m\u001b[33m\"\u001b[39m, response.text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 234\u001b[39m, in \u001b[36mrequest_cc\u001b[39m\u001b[34m(client, chat, input_data, jwt_token)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse JSON:\u001b[39m\u001b[33m\"\u001b[39m, response.json())\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[43mcreate_chart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m json.decoder.JSONDecodeError:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse Text:\u001b[39m\u001b[33m\"\u001b[39m, response.text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 250\u001b[39m, in \u001b[36mcreate_chart\u001b[39m\u001b[34m(client, chat, input)\u001b[39m\n\u001b[32m    239\u001b[39m system_instruction = (\n\u001b[32m    240\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mI would like you to generate the chart by yourself by writing your own code and exporting the final result as image to me \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe response (chart input) are as follows:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mjust use the response provided to create the chart, dont show me the steps, elaborate or ask for additional input. All I need is the chart image and the statistics as text as response\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m )\n\u001b[32m    248\u001b[39m \u001b[38;5;28mprint\u001b[39m(system_instruction)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 280\u001b[39m, in \u001b[36mgenerate\u001b[39m\u001b[34m(client, input)\u001b[39m\n\u001b[32m    264\u001b[39m contents = [\n\u001b[32m    265\u001b[39m     types.Content(\n\u001b[32m    266\u001b[39m         role=\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m     ),\n\u001b[32m    271\u001b[39m ]\n\u001b[32m    272\u001b[39m generate_content_config = types.GenerateContentConfig(\n\u001b[32m    273\u001b[39m     response_modalities=[\n\u001b[32m    274\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     response_mime_type=\u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    278\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_content_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\models.py:5441\u001b[39m, in \u001b[36mModels.generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5435\u001b[39m function_map = _extra_utils.get_function_map(config)\n\u001b[32m   5437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m1\u001b[39m:\n\u001b[32m   5438\u001b[39m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[32m   5439\u001b[39m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[32m   5440\u001b[39m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5441\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5442\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5443\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\models.py:4343\u001b[39m, in \u001b[36mModels._generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4340\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4341\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4343\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_streamed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4344\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4347\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_GenerateContentResponse_from_vertex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4349\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_dict\u001b[49m\n\u001b[32m   4350\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:594\u001b[39m, in \u001b[36mBaseApiClient.request_streamed\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest_streamed\u001b[39m(\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    585\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    588\u001b[39m     http_options: Optional[HttpOptionsDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    589\u001b[39m ):\n\u001b[32m    590\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    591\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    592\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m   session_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    595\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response.segments():\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:488\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    484\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    485\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    486\u001b[39m   )\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_unauthorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:511\u001b[39m, in \u001b[36mBaseApiClient._request_unauthorized\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    502\u001b[39m http_session = requests.Session()\n\u001b[32m    503\u001b[39m response = http_session.request(\n\u001b[32m    504\u001b[39m     method=http_request.method,\n\u001b[32m    505\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     stream=stream,\n\u001b[32m    510\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    513\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    514\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raviteja.chandu.LHP-LW0-11SC5S2\\GeminiAPITest\\venv\\Lib\\site-packages\\google\\genai\\errors.py:116\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    114\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    118\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response)\n",
      "\u001b[31mServerError\u001b[39m: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}"
     ]
    }
   ],
   "source": [
    "# Send first message with system instruction + actual user query\n",
    "system_instruction = (\n",
    "    \"You are an interface for an agent connected to a BI Tool called Command Center. \"\n",
    "    \"First, check if the user's question is relevant for a BI tool. \"\n",
    "    \"If it's not, create a json with relevance and the then just answer it as best you can in the json frame. \"\n",
    "    \"If it is relevant, answer yes and then check if the necessary data (like timeframe and BI variable) is provided. \"\n",
    "    \"If all data is present, create a JSON object with the data presence as yes and with the variable name, time start in 24hr format, and time end in 24hr format. else create a json similar json as before but with data presence as no and variable also asking the user to input more information \\n\\n\"\n",
    ")\n",
    "\n",
    "#user_question = \"How many users signed up between 9:00 and 17:00 yesterday?\"\n",
    "#user_question = \"who is the pope?\"\n",
    "#user_question = \"whats the production? capacity\"\n",
    "user_question = input(\"User Input: \")\n",
    "\n",
    "\n",
    "\n",
    "response = chat.send_message(system_instruction + user_question)\n",
    "\n",
    "# Print chat\n",
    "print(\"User:\", user_question)\n",
    "print(\"Assistant:\", response.text)\n",
    "\n",
    "extract_json(client,chat,response, jwt_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n  \"relevance\": \"yes\",\\n  \"data_presence\": \"no\",\\n  \"variable_name\": \"production\",\\n  \"missing_information\": \"Please specify the timeframe for the production data you are interested in (e.g., \\'last week\\', \\'today\\', \\'this month\\').\"\\n}\\n```\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.10746549271248482, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=74, prompt_token_count=153, total_token_count=227) automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted JSON: {'relevance': 'yes', 'data_presence': 'no', 'variable_name': 'production/production capacity', 'missing_information': \"Please specify which you're interested in - production or production capacity - and provide a timeframe (e.g., last week, last month, specific dates).\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Extract the JSON block\n",
    "match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", response.text, re.DOTALL)\n",
    "if match:\n",
    "    json_str = match.group(1)\n",
    "    data = json.loads(json_str)\n",
    "    print(\"Extracted JSON:\", data)\n",
    "        \n",
    "    # Route logic based on relevance\n",
    "    if data.get(\"relevance\", \"\").lower() == \"yes\":\n",
    "        handle_bi_relevant(data)\n",
    "    else:\n",
    "        handle_non_bi_query(data)\n",
    "else:\n",
    "    print(\"No JSON found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now that you have extracted the relevant variable name for BI relevant queries, I want you to compare it with the datsets present in the BI tool  The variable name is abc.The datasets are provided in the end If the variable is either directly present or can be calculated using multiple variables present in one dataset, create a json with if the dataset ahs been found as boolean and the name of the dataset \n"
     ]
    }
   ],
   "source": [
    "variable = \"abc\"\n",
    "system_instruction = (\n",
    "    f\"Now that you have extracted the relevant variable name for BI relevant queries, I want you to compare it with the datsets present in the BI tool \"\n",
    "    f\" The variable name is {variable}.\"\n",
    "    f\"The datasets are provided in the end \"\n",
    "    f\"If the variable is either directly present or can be calculated using multiple variables present in one dataset, create a json with if the dataset ahs been found as boolean and the name of the dataset \"\n",
    "    )\n",
    "print(system_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how AI works in a way that's understandable, even if you don't have a computer science background.  I'll try to avoid getting too technical, but I'll also give you some core concepts.\n",
      "\n",
      "**The Basic Idea: Mimicking Intelligence**\n",
      "\n",
      "At its heart, Artificial Intelligence (AI) is about creating computer systems that can perform tasks that typically require human intelligence. This includes things like:\n",
      "\n",
      "*   **Learning:**  Improving performance over time based on data.\n",
      "*   **Reasoning:**  Drawing conclusions from information.\n",
      "*   **Problem Solving:** Finding solutions to complex issues.\n",
      "*   **Perception:** Understanding sensory input (like images, sound, or text).\n",
      "*   **Natural Language Processing:** Understanding and generating human language.\n",
      "\n",
      "**Key Components & Approaches**\n",
      "\n",
      "Think of AI as an umbrella term covering a lot of different techniques. Here are some of the most important:\n",
      "\n",
      "1.  **Machine Learning (ML): The Learning Engine**\n",
      "\n",
      "    *   **What it is:** Machine learning is the most common way to achieve AI. Instead of explicitly programming a computer to do something, you *train* it using large amounts of data. The algorithm learns patterns from the data and then uses those patterns to make predictions or decisions on new, unseen data.\n",
      "\n",
      "    *   **How it works (Simplified):**\n",
      "\n",
      "        *   **Data Input:** You feed the algorithm a dataset (e.g., images of cats and dogs, customer purchase histories, text from news articles).\n",
      "        *   **Feature Extraction:** The algorithm (or you) identifies important features in the data (e.g., for images: edges, colors, textures; for text: words, phrases, sentiment).\n",
      "        *   **Model Building:** The algorithm builds a model (a mathematical representation) that maps the input features to the desired output (e.g., cat or dog, predict future sales, identify the topic of an article).\n",
      "        *   **Training:** The algorithm adjusts the model's parameters to minimize errors in its predictions. This is often done using a feedback loop where the algorithm makes a prediction, compares it to the correct answer, and then adjusts its parameters to get closer to the correct answer next time.\n",
      "        *   **Testing/Evaluation:**  You test the model on a separate set of data (that it hasn't seen before) to see how well it generalizes.\n",
      "        *   **Deployment:** If the model performs well, you deploy it to make predictions on new data.\n",
      "\n",
      "    *   **Types of Machine Learning:**\n",
      "\n",
      "        *   **Supervised Learning:**  You give the algorithm labeled data (e.g., \"this image is a cat,\" \"this customer churned\"). The algorithm learns to predict the labels for new data.  Examples: image classification, spam detection, regression (predicting a numerical value).\n",
      "        *   **Unsupervised Learning:** You give the algorithm unlabeled data (e.g., a bunch of customer data without telling it which customers are similar). The algorithm tries to find patterns and structures in the data on its own. Examples: clustering (grouping similar customers), dimensionality reduction (simplifying complex data), anomaly detection (finding unusual events).\n",
      "        *   **Reinforcement Learning:**  The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. Think of it like training a dog with treats. Examples: game playing (like AlphaGo), robotics, autonomous driving.\n",
      "\n",
      "2.  **Deep Learning (DL):  The Powerhouse of Modern AI**\n",
      "\n",
      "    *   **What it is:** Deep learning is a subfield of machine learning that uses artificial neural networks with many layers (hence \"deep\").  These networks are inspired by the structure of the human brain.\n",
      "\n",
      "    *   **How it works (Simplified):**\n",
      "\n",
      "        *   Deep neural networks consist of interconnected nodes (neurons) organized in layers.\n",
      "        *   Input data is fed into the first layer.\n",
      "        *   Each neuron performs a simple calculation on its inputs and passes the result to the neurons in the next layer.\n",
      "        *   As the data passes through the layers, the network learns to extract increasingly complex features from the data.\n",
      "        *   The final layer outputs the prediction.\n",
      "\n",
      "    *   **Why it's powerful:** Deep learning can automatically learn complex features from raw data, without needing manual feature engineering. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition.  However, it typically requires a *lot* of data and computational power.\n",
      "\n",
      "3.  **Natural Language Processing (NLP):  Understanding and Generating Language**\n",
      "\n",
      "    *   **What it is:** NLP focuses on enabling computers to understand, interpret, and generate human language.\n",
      "\n",
      "    *   **Examples:**\n",
      "\n",
      "        *   **Machine Translation:** Translating text from one language to another (e.g., Google Translate).\n",
      "        *   **Sentiment Analysis:** Determining the emotional tone of a piece of text (e.g., positive, negative, neutral).\n",
      "        *   **Chatbots:**  Creating conversational agents that can interact with humans.\n",
      "        *   **Text Summarization:**  Generating a concise summary of a longer text.\n",
      "        *   **Speech Recognition:** Converting spoken language into text.\n",
      "        *   **Text Generation:** Creating new text, such as articles, stories, or code.\n",
      "\n",
      "    *   **Techniques:** NLP uses a combination of machine learning, deep learning, and linguistic rules to process language.\n",
      "\n",
      "4.  **Computer Vision:  Seeing Like a Computer**\n",
      "\n",
      "    *   **What it is:** Computer vision enables computers to \"see\" and interpret images and videos.\n",
      "\n",
      "    *   **Examples:**\n",
      "\n",
      "        *   **Object Detection:** Identifying objects in an image (e.g., cars, pedestrians, trees).\n",
      "        *   **Image Recognition:** Classifying an image (e.g., \"this is a cat\").\n",
      "        *   **Facial Recognition:** Identifying faces in an image.\n",
      "        *   **Image Segmentation:** Dividing an image into regions (e.g., separating the foreground from the background).\n",
      "\n",
      "    *   **Techniques:** Computer vision heavily relies on deep learning, particularly convolutional neural networks (CNNs), to analyze images.\n",
      "\n",
      "5.  **Rule-Based Systems (Expert Systems): The Old School Approach**\n",
      "\n",
      "    *   **What it is:** These systems use a set of predefined rules to make decisions.  They are based on human expertise.\n",
      "\n",
      "    *   **How it works:**\n",
      "        *   A knowledge engineer interviews experts in a specific domain and translates their knowledge into a set of \"if-then\" rules.\n",
      "        *   The system uses these rules to reason about new situations and provide recommendations.\n",
      "\n",
      "    *   **Limitations:**  Rule-based systems are good for well-defined problems with limited complexity, but they are difficult to scale and maintain when the problem domain is large or constantly changing. They also lack the ability to learn from data.  Less common now, but still used in some specific applications.\n",
      "\n",
      "**The AI Development Process (General Outline)**\n",
      "\n",
      "1.  **Define the Problem:** What specific task do you want the AI to perform?\n",
      "2.  **Gather Data:** Collect a large and relevant dataset for training.  Data quality is crucial!\n",
      "3.  **Choose an Algorithm/Approach:** Select the appropriate machine learning algorithm or AI technique based on the problem and the data.\n",
      "4.  **Train the Model:** Train the algorithm on the data to build a model.\n",
      "5.  **Evaluate the Model:** Test the model on a separate dataset to assess its performance.\n",
      "6.  **Tune the Model:** Adjust the model's parameters to improve its accuracy and performance.\n",
      "7.  **Deploy the Model:** Integrate the model into a real-world application.\n",
      "8.  **Monitor and Maintain:** Continuously monitor the model's performance and retrain it as needed to keep it up-to-date.\n",
      "\n",
      "**Important Considerations**\n",
      "\n",
      "*   **Data is King:** AI models are only as good as the data they are trained on.  Biased data can lead to biased models.\n",
      "*   **Computational Power:** Training complex AI models, especially deep learning models, requires significant computational resources (GPUs, TPUs).\n",
      "*   **Explainability:**  Understanding *why* an AI model makes a particular decision is important, especially in critical applications (e.g., healthcare, finance).  This is an area of active research (Explainable AI or XAI).\n",
      "*   **Ethics:** AI raises ethical concerns about bias, fairness, privacy, and job displacement.  It's important to develop and use AI responsibly.\n",
      "\n",
      "**In Summary**\n",
      "\n",
      "AI is a broad field that aims to create intelligent machines. Machine learning, especially deep learning, is the most common approach. These techniques involve training algorithms on large datasets to learn patterns and make predictions.  NLP and computer vision are important subfields that focus on enabling computers to understand language and images, respectively.  The key is to define the problem clearly, gather good data, choose the right algorithm, and evaluate and tune the model carefully.\n",
      "\n",
      "This is a simplified overview, but I hope it gives you a good understanding of how AI works! Let me know if you have any more specific questions.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"Explain how AI works\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful! Dogs bring so much joy to a home. Do you want to tell me anything else about them? Like their names, breeds, or favorite activities?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since you have two dogs, and each dog has four paws, there are a total of 8 paws in your house.\n",
      "\n",
      "role - user: I have 2 dogs in my house.\n",
      "role - model: That's wonderful! Dogs bring so much joy to a home. Do you want to tell me anything else about them? Like their names, breeds, or favorite activities?\n",
      "\n",
      "role - user: How many paws are in my house?\n",
      "role - model: Since you have two dogs, and each dog has four paws, there are a total of 8 paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f'role - {message.role}',end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
